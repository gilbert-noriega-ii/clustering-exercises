{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquire & Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from acquire import get_connection, get_zillow_data\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Acquire data from mySQL using the python module to connect and query. You will want to end with a single dataframe. \n",
    "- Make sure to include: the logerror, all fields related to the properties that are available. You will end up using all the tables in the database.\n",
    "- Be sure to do the correct join (inner, outer, etc.). We do not want to eliminate properties purely because they may have a null value for airconditioningtypeid.\n",
    "- Only include properties with a transaction in 2017, and include only the last transaction for each properity (so no duplicate property ID's), along with zestimate error and date of transaction.\n",
    "- Only include properties that include a latitude and longitude value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_zillow_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Summarize your data \n",
    "- (summary stats, info, dtypes, shape, distributions, value_counts, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.columns[[59]], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Takeaways:\n",
    "    \n",
    "- Dropping duplicated id columns\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if df[col].dtype != object:\n",
    "        plt.figure(figsize=(4,3))\n",
    "        plt.hist(df[col])\n",
    "        plt.title(col)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print(\"\\n\")\n",
    "    print(df[col].value_counts())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Write a function that takes in a dataframe of observations and attributes and returns a dataframe where \n",
    "- each row is an atttribute name\n",
    "- the first column is the number of rows with missing values for that attribute\n",
    "- the second column is percent of total rows that have missing values for that attribute. \n",
    "- Run the function and document takeaways from this on how you want to handle missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_finder_columns(df):\n",
    "    '''\n",
    "    This function takes in a DataFrame and list \n",
    "    information about the null values in the columns\n",
    "    '''\n",
    "    #accepts a 'df' and creates a new one labeled 'nulls'  \n",
    "    #nulls index is the df's columns\n",
    "    nulls = pd.DataFrame(index = df.columns)\n",
    "    #sums up the null values in the dataframes columns\n",
    "    nulls['num_rows_missing'] = df.isnull().sum(axis = 0)\n",
    "    #finds the percentage of null values in the df's columns\n",
    "    nulls['pct_rows_missing'] = nulls.num_rows_missing / df.shape[0]\n",
    "    return nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_columns = null_finder_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_columns.sort_values(by = 'pct_rows_missing', ascending = False).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Takeaways: \n",
    "    \n",
    "- There are 34 out of the 68 columns missing more than half the value\n",
    "    \n",
    "- May need to drop a lot of the data  \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Write a function that takes in a dataframe and returns a dataframe with 3 columns: \n",
    "- the number of columns missing, \n",
    "- percent of columns missing, \n",
    "- number of rows with n columns missing. \n",
    "- Run the function and document takeaways from this on how you want to handle missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_finder_rows(df):\n",
    "    '''\n",
    "    This function finds the number of columns missing in a row,\n",
    "    the percent of columns missing in the row\n",
    "    and the number of rows that have the same amount of columns missing\n",
    "    '''\n",
    "    #initiate a dataframe\n",
    "    rows = pd.DataFrame()\n",
    "    #find the number of columns missing in the row\n",
    "    rows['num_cols_missing'] = df.isnull().sum(axis=1)\n",
    "    #find the percentage of columns missing in the row\n",
    "    rows['pct_cols_missing'] = df.isnull().sum(axis=1) / df.shape[1]\n",
    "    #group by 'num_cols_missing' and find \n",
    "    #how many rows have that number of columns missing\n",
    "    num_rows = rows.groupby('num_cols_missing').count()\n",
    "    #rename the column as 'num_rows'\n",
    "    num_rows = num_rows.rename(columns ={'pct_cols_missing': \"num_rows\"})\n",
    "    #group by 'num_cols_missing' and find \n",
    "    #the percentage of columns missing in the row\n",
    "    pct_cols = rows.groupby('num_cols_missing').mean()\n",
    "    #combine the 'pct_cols' and 'num_rows'\n",
    "    result = pd.concat([pct_cols, num_rows], axis=1, sort=False)\n",
    "    #take the 'num_cols_missing' out of the index\n",
    "    result = result.reset_index()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_rows = null_finder_rows(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_rows.sort_values(by = 'pct_cols_missing', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Takeaways:\n",
    "\n",
    "- Below 60% is a major jump in rows missing\n",
    "\n",
    "- This will be the threshold \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Remove any properties that are likely to be something other than single unit properties. (e.g. no duplexes, no land/lot, ...).\n",
    "- There are multiple ways to estimate that a property is a single unit, and there is not a single \"right\" answer. But for this exercise, do not purely filter by unitcnt as we did previously. \n",
    "- Add some new logic that will reduce the number of properties that are falsely removed. \n",
    "- You might want to use # bedrooms, square feet, unit type or the like to then identify those with unitcnt not defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.propertylandusedesc.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Takeaways:\n",
    "\n",
    "- keep only single family residential(261), residential general(260) \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.propertylandusetypeid.isin([260,261])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check bedroom and bathroom counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.bedroomcnt.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.bathroomcnt.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Takeaways:\n",
    "\n",
    "- 178 houses had either 0 as bedroom or bathroom\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.bedroomcnt > 0) & (df.bathroomcnt > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.unitcnt.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Takeaways:\n",
    "\n",
    "- 18541 null unit counts. They are probably unit counts of 1.\n",
    "\n",
    "- Filter out the units that are more than one\n",
    "\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.unitcnt = df.unitcnt.fillna(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.unitcnt == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.unitcnt != 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a function that will drop rows or columns based on the percent of values that are missing: handle_missing_values(df, prop_required_column, prop_required_row).\n",
    "\n",
    "- The input:\n",
    "    - A dataframe\n",
    "    - A number between 0 and 1 that represents the proportion, for each column, of rows with non-missing values required to keep the column. i.e. if prop_required_column = .6, then you are requiring a column to have at least 60% of values not-NA (no more than 40% missing).\n",
    "    - A number between 0 and 1 that represents the proportion, for each row, of columns/variables with non-missing values required to keep the row. For example, if prop_required_row = .75, then you are requiring a row to have at least 75% of variables with a non-missing value (no more that 25% missing).\n",
    "- The output:\n",
    "    - The dataframe with the columns and rows dropped as indicated. Be sure to drop the columns prior to the rows in your function.\n",
    "- hint:\n",
    "    - Look up the dropna documentation.\n",
    "    - You will want to compute a threshold from your input values (prop_required) and total number of rows or columns.\n",
    "    - Make use of inplace, i.e. inplace=True/False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df, prop_required_column, prop_required_row):\n",
    "    thresh_col = int(round(prop_required_column*df.shape[0],0))\n",
    "    df.dropna(axis=1, thresh=thresh_col, inplace=True)\n",
    "    thresh_row = int(round(prop_required_row*df.shape[1],0))\n",
    "    df.dropna(axis=0, thresh=thresh_row, inplace=True)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = handle_missing_values(df, .6, .6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Decide how to handle the remaining missing values:\n",
    "\n",
    "   - Fill with constant value.\n",
    "   - Impute with mean, median, mode.\n",
    "   - Drop row/column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Takeaways:\n",
    "\n",
    "- dropping typeid that are no longer needed\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"id\", \"propertylandusetypeid\", \"heatingorsystemtypeid\", \"unitcnt\", \"propertylandusedesc\", \"propertycountylandusecode\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Takeaways:\n",
    "\n",
    "- propertyzoningdesc = Description of the allowed land uses (zoning) for that property\n",
    "- dropping because we already filtered for single unit residential.\n",
    "- let's take a closer look into the missing values\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"propertyzoningdesc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.heatingorsystemdesc.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Takeaways:\n",
    "\n",
    "- In southern California, the NaN values are most likely no type of heating system\n",
    "\n",
    "- We will fill Nan with none\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.heatingorsystemdesc = df.heatingorsystemdesc.fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.calculatedbathnbr == df.bathroomcnt).sum() / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Takeaways:\n",
    "\n",
    "- Looks like calculatedbathrbr is equivalent to bathroomcnt\n",
    "- drop the duplicate column\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"calculatedbathnbr\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Takeaways:\n",
    "\n",
    "- We have dropped all we can\n",
    "- To fill the rest of the NaNs we should split the data\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.finishedsquarefeet12 == df.calculatedfinishedsquarefeet).sum() / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Takeaways:\n",
    "\n",
    "- Looks like finishedsquarefeet12 is equilalent to calculatedfinishedsqurefeet\n",
    "- drop the duplicate column\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['finishedsquarefeet12'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['county'] = df.fips.replace([6037, 6059, 6111],['los_angeles', 'orange', 'ventura'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['fips'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Takeaways:\n",
    "\n",
    "- change fips number to a category labeled by county\n",
    "- drop the duplicate column\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Validate, and Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_and_validate, test = train_test_split(df, train_size=.8, random_state=123)\n",
    "train, validate = train_test_split(train_and_validate, train_size = .7, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().sort_values(ascending = False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Takeaways:\n",
    "\n",
    "- We will divide the remaining nulls into two columns\n",
    "    - The fixed values will use the mode\n",
    "    - the continuous values will use the median\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_fixed = [\n",
    "    'buildingqualitytypeid',\n",
    "    'regionidcity',\n",
    "    'censustractandblock',\n",
    "    'regionidzip',\n",
    "    'yearbuilt'\n",
    "]\n",
    "\n",
    "\n",
    "for col in cols_fixed:\n",
    "    mode = int(train[col].mode())\n",
    "    train[col].fillna(value = mode, inplace = True)\n",
    "    validate[col].fillna(value = mode, inplace = True)\n",
    "    test[col].fillna(value = mode, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum().sort_values(ascending = False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_cont = [\n",
    "    'lotsizesquarefeet',\n",
    "    'structuretaxvaluedollarcnt',\n",
    "    'fullbathcnt',\n",
    "    'calculatedfinishedsquarefeet',\n",
    "    'taxamount',\n",
    "    'landtaxvaluedollarcnt',\n",
    "    'taxvaluedollarcnt'\n",
    "]\n",
    "\n",
    "\n",
    "for col in cols_cont:\n",
    "    median = train[col].median()\n",
    "    train[col].fillna(median, inplace=True)\n",
    "    validate[col].fillna(median, inplace=True)\n",
    "    test[col].fillna(median, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since there are no more null values and the data is prepped, we can write the output to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train.to_csv(\"zillow_train.csv\")\n",
    "validate.to_csv(\"zillow_validate.csv\")\n",
    "test.to_csv(\"zillow_test.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
